# SPDX-FileCopyrightText: Copyright (c) 2021-2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
%YAML 1.2
---
dependencies:
- extension: StandardExtension
  uuid: 8ec2d5d6-b5df-48bf-8dee-0252606fdd7e
  version: 2.0.0
- extension: CudaExtension
  uuid: d63a98fa-7882-11eb-a917-b38f664f399c
  version: 1.0.1
- extension: PythonCodeletExtension
  uuid: 787daddc-1c34-11ec-9621-0242ac130002
  version: 2.0.0
---
name: global
components:
- name: stream_pool
  type: nvidia::gxf::CudaStreamPool
  parameters:
    stream_flags: 0
    stream_priority: 0
    reserved_size: 1
    max_size: 5
- name: cuda_pool
  type: nvidia::gxf::BlockMemoryPool
  parameters:
    storage_type: 1 # cuda
    block_size: 8388608
    num_blocks: 5
- name: host_pool
  type: nvidia::gxf::BlockMemoryPool
  parameters:
    storage_type: 0 # host
    block_size: 8388608
    num_blocks: 5
- name: cuda_dot_pool
  type: nvidia::gxf::BlockMemoryPool
  parameters:
    storage_type: 1 # cuda
    block_size: 16384
    num_blocks: 10
- name: host_dot_pool
  type: nvidia::gxf::BlockMemoryPool
  parameters:
    storage_type: 0 # host
    block_size: 16384
    num_blocks: 10
---
name: stream_tensor_generator
components:
- name: host_out
  type: nvidia::gxf::DoubleBufferTransmitter
- name: cuda_out
  type: nvidia::gxf::DoubleBufferTransmitter
- name: generator
  type: nvidia::gxf::test::cuda::StreamTensorGenerator
  parameters:
    cuda_tx: cuda_out
    host_tx: host_out
    cuda_tensor_pool: global/cuda_pool
    host_tensor_pool: global/host_pool
    stream_pool: global/stream_pool
- type: nvidia::gxf::DownstreamReceptiveSchedulingTerm
  parameters:
    transmitter: cuda_out
    min_size: 1
- type: nvidia::gxf::DownstreamReceptiveSchedulingTerm
  parameters:
    transmitter: host_out
    min_size: 1
- type: nvidia::gxf::CountSchedulingTerm
  parameters:
    count: 50
---
name: cuda_dotproduct
components:
- name: rx
  type: nvidia::gxf::DoubleBufferReceiver
  parameters:
    capacity: 2
- name: tx
  type: nvidia::gxf::DoubleBufferTransmitter
- type: nvidia::gxf::MessageAvailableSchedulingTerm
  parameters:
    receiver: rx
    min_size: 1
- type: nvidia::gxf::DownstreamReceptiveSchedulingTerm
  parameters:
    transmitter: tx
    min_size: 1
- type: nvidia::gxf::test::cuda::CublasDotProduct
  parameters:
    rx: rx
    tx: tx
    tensor_pool: global/cuda_dot_pool
---
name: host_dotproduct
components:
- name: rx
  type: nvidia::gxf::DoubleBufferReceiver
  parameters:
    capacity: 2
- name: tx
  type: nvidia::gxf::DoubleBufferTransmitter
- type: nvidia::gxf::MessageAvailableSchedulingTerm
  parameters:
    receiver: rx
    min_size: 1
- type: nvidia::gxf::DownstreamReceptiveSchedulingTerm
  parameters:
    transmitter: tx
    min_size: 1
- type: nvidia::gxf::test::cuda::HostDotProduct
  parameters:
    rx: rx
    tx: tx
    tensor_pool: global/host_dot_pool
---
name: streamsync
components:
- name: rx
  type: nvidia::gxf::DoubleBufferReceiver
- name: tx
  type: nvidia::gxf::DoubleBufferTransmitter
- type: nvidia::gxf::MessageAvailableSchedulingTerm
  parameters:
    receiver: rx
    min_size: 1
- type: nvidia::gxf::DownstreamReceptiveSchedulingTerm
  parameters:
    transmitter: tx
    min_size: 1
- type: nvidia::gxf::CudaStreamSync
  parameters:
    rx: rx
    tx: tx
---
name: verify_equal
components:
- name: rx0
  type: nvidia::gxf::DoubleBufferReceiver
- name: rx1
  type: nvidia::gxf::DoubleBufferReceiver
- type: nvidia::gxf::PyCodeletV0
  parameters:
    codelet_name: VerifyEqual
    codelet_file: gxf/python/tests/VerifyEqual.py
    codelet_params:
      clock: scheduler/clock
      receiver0: rx0
      receiver1: rx1
- type: nvidia::gxf::MessageAvailableSchedulingTerm
  parameters:
    receiver: rx0
    min_size: 1
- type: nvidia::gxf::MessageAvailableSchedulingTerm
  parameters:
    receiver: rx1
    min_size: 1
- name: step_count
  type: nvidia::gxf::PyCodeletV0
  parameters:
    codelet_name: StepCount
    codelet_file: gxf/python/tests/StepCount.py
    codelet_params:
      expected_count: 50
---
components:
- type: nvidia::gxf::Connection
  parameters:
    source: stream_tensor_generator/host_out
    target: host_dotproduct/rx
---
components:
- type: nvidia::gxf::Connection
  parameters:
    source: stream_tensor_generator/cuda_out
    target: cuda_dotproduct/rx
---
components:
- type: nvidia::gxf::Connection
  parameters:
    source: cuda_dotproduct/tx
    target: streamsync/rx
---
components:
- type: nvidia::gxf::Connection
  parameters:
    source: streamsync/tx
    target: verify_equal/rx0
---
components:
- type: nvidia::gxf::Connection
  parameters:
    source: host_dotproduct/tx
    target: verify_equal/rx1
---
name: scheduler
components:
- name: clock
  type: nvidia::gxf::ManualClock
- type: nvidia::gxf::GreedyScheduler
  parameters:
    clock: clock
    max_duration_ms: 1000
# Resources
# GPU
---
# only the first will be used by default EntityGroup
name: GPU_0
components:
- type: nvidia::gxf::GPUDevice
  name: GPU_0
  parameters:
    dev_id: 0